---
title: "Homework for Chapter 18: Difference-in-Differences"
author: "Braulio Guemez"
date: "3/2/2022"
output: html_document
---

# Homework 9

### 0. Libraries
```{r,message=FALSE,results='hide'}
library(dplyr) 
library(gt) ## for nice tables 
library(ggplot2)
library(ggthemes)
library(broom) ## for tidy
library(modelsummary)
library(fixest) ##for two-way fixed effects

```


## How does it work?


### 1.	In the Event Studies chapter we estimated the effect of something that occurs at a specific time by just comparing before-event to after-event, without really using a control group. What assumption is made by no-control-group event studies that we don’t have to make with difference-in-differences?

_We make the assumption that the treatment was the ONLY thing that changed during the time period of study. In other words, we assume that the pattern in time would have remained the same had the treatment did not occur._

_In DID we don't have to assume that because we have a similar group to compare (the control group). If the parallel trend assumption holds, then we can confidently say that during the period of treatment there was not anything else that changed during time, except for thet treatment._



### 2.	Which of the following potential back doors is controlled for by comparing the treated group to a control group?

_b.	There may be events affecting everyone that would change the outcome from before-treatment to after-treatment anyway_

### 3. Consider a treatment and control group. Looking only at the pre-treatment period, they have exactly the same outcomes (zero gap between them in each period).


#### a.	Despite having exactly the same outcomes pre-treatment, it happens to be the case that parallel trends is violated for these two groups. How is this possible? Explain what it means for parallel trends to be violated in this case, or give an example of how it could be violated.

_It might be that the untreated group suddenly changed at the moment of the treatment, which would violate the assumption. For example, suppose we are seeing patterns of meat consumption in two cities, and we want to estimate the effect of a news article alerting for a salmonella outbreak in chicken meat in one of the cities. The two cities had the same meat consumption levels, but at the time of the news outbreak, there was a chicken shortage on the untreated group, which brought the meat consumption levels down. The two groups are not comparable anymore and the parallel trend assumption is violated: had the treatment not occurred, the cities would have NOT continued having similar trends_


#### b.	If we estimate the causal effect in this case using difference-in-differences, even though parallel trends is violated, how much would our effect be off by? (note you won’t be able to give a specific number)

_In my example of meat consumption, the effect of the news article could even also lead to think that it increased meat consumption, because it would be compared to very low levels of it on the untreated group._   


### 4. Consider the below graph showing the average outcome for treated and control groups in the leadup to treatment (indicated by the dashed line), and also after treatment.

#### a.	Based on the prior trend, does it seem likely that parallel trends holds in this instance?

_No, the gap between the two reduces in size by the time of the treatment. There is too much variation for the parallel assumption to hold._ 


#### b.	If we estimate difference-in-differences anyway, are we likely to overestimate the actual causal effect, underestimate it, or get it right on average?

_I think we will underestimate the effect. The reason is that the treatment seems to have had a positive effect, but, because the untreated group was having an upward tendency, we would mistakenly think that was en effect of "time" and reduce the positive effect on the treatment group_

### 5.	In mid-2020, during the COVID-19 pandemic, different countries pursued different courses of action. Some locked down fully, imposing harsh penalties to most people for leaving the house outside certain proscribed times. Some were looser and only suggested staying at home, and some had hardly any restrictions at all. You notice that COVID rates tend to spike dramatically in different countries at seemingly-random times, and want to know if certain restrictions helped.

From March through May 2020, US and Canada COVID case rates followed similar trends (US rates were higher, but the trends were similar). You want to look at the effect of COVID restrictions enacted in Canada in late May 2020 on case rates. Is DID, with the US as a control group, a good way to estimate this effect? If not, what concerns would you have about this research design?

_Maybe not, because we would have to assume that the US did not do anything at the same time as Canada. One of the features of COVID policies is that many countries copy each other in the "right" way of doing things, so the fact that Canada does something might affect how the US also reacts to the pandemic. The assumptions of parallel trends would be violated_


### 6.	Consider the below table of mean outcomes, and calculate the difference-in-difference effect of treatment. Write out the equation you used to calculate it (i.e. show how the four numbers in the table are combined to get the estimate)

```{r}
tibble(treat=c(1,0),before=c(5,6),after=c(9,7.5)) |> gt()
```


```{r}
## Step 1: find time effect on the untreated group

  time <- 7.5-6

## Step 2: Remove time effect from outcome in the treated & untreated group
  adj_post_tr <- 9 - time
  adj_post_un <-7.5 - time
  
## Step 3: estimate before/after diff in treated group
  
  adj_post_tr - 5
  

  ### Easier way
  
  #See diff on the treated group and remove the diff of the untreated group  
  (9-5) - (7.5-6)
  
  
```






## How is it performed?

### 1.	You are planning to estimate whether voter-protection laws increase voter turnout. You note that, in 2015, a lot of new voter-protection laws were enacted in some provinces but not in others. Conveniently, no new laws were enacted in 2012, 2014, or 2016, so you decide to use 2012 and 2014 as your “before” periods and 2016 as “after”. 


#### a.	Which of the following best describes what you’d want to regress state-and-year level “voter turnout” measures on?


_iv.	A set of fixed effects for state, and for year, and an interaction between “is 2016” and “is a treated state"_



#### b.	Unless you chose the final option in the previous question, specify which coefficient in that regression would give you the DID estimate.

_The interaction between being in the post-treatment period and being treated_

### 2.	You are looking at a difference-in-difference design to estimate the effect of providing laptops to school children on their test scores. Look at the below regression output, in which “Treated” is an indicator that the school received laptops in 2008 as part of a new program (the untreated group did not receive any laptops until years after the sample window for this study ended), and “After” is an indicator for being after the year 2008.Using the table, fill in the blanks in the sentence



_Assuming that *test scores remain constant over time on the untreated group*, the effect of laptops on test scores was *5.034+4.116=9.15*, and this effect *was* statistically significant at the 95% level.”_



### 3. 	A standard “prior trends” test might estimate a regression using the model Y= β_0+β_1 t+β_2 Treated+β_3 t×Treated+ε (only using data from before-treatment), where t is a time variable, Treated is an indicator for being in the treated group, and Y is an outcome variable, and look for a large/significant estimate of β_3. Explain why this test is performed, and specifically what it shows.

_This test is performed to see if the groups on the research design had different trends on the pre-treatment period. We want to see if the B3 coefficient is different than zero, because that would inform us if the effect of time was different between groups in the pre-treatment period. If that is the case, then the parallel trend assumption would be in danger_  



### 4.	Consider the below graph with estimates from a dynamic difference-in-differences model for a treatment that occurs between periods 4 and 5, with 95% confidence intervals shown.

####a.	What about this graph might make us concerned about our identification assumptions?

_There is a pre-treatment period effect in time 1. This violates the parallel trend assumption because it doesn't pass the placebo test_


####b.	Ignoring any concerns we have, what would we say is the effect of treatment on Y in this case? (note the height of the line in period 5 is about 3, in period 6 is about 1, and in period 7 is about .5).

_It would be equal to the average of the effects from the three periods, so (5+1+.6)/3 = 2.2_

### 5.	Chapter 18.2.5 points out a problem with two-way fixed effects in cases where treatment is not all assigned at the same time, but rather different groups get treated at different times (a “rollout” design). In these designs, two-way fixed effects treats “already-treated” units, who were treated in earlier periods, as “control” units, as though they hadn’t gotten treated at all.

However, there’s nothing theoretically wrong about using an already-treated unit as a control; the DID assumptions don’t require that the control group be untreated, just that the gap between treated and control doesn’t change when the treated group’s treatment goes into effect. Why are we so concerned, then, about using an already-treated group as a control? You can answer generally, or use as an example a DID with only two groups – an already-treated group and a newly-treated group. (hint: to do the example, try assuming the treatment only has an effect for the single period after treatment, and the already-treated group is treated exactly one period before the treated group)


_Because the effect of the already-treated group can be dynamic and change by the time the treated group gets the treatment. This will mess up with the parallel trends assumption._



## Coding homework


### 1. In this assignment we will be walking through a very simple application of difference-in-differences that comes from Peter Nencka. In particular, it seemed that the beginning of the COVID-19 pandemic led to a brief craze for homemade sourdough bread, as people had to stay home, and stores were out of yeast (sourdough can be made at home using yeast from the air and does not require store-bought yeast). We will be estimating whether COVID lockdowns actually increased interest in sourdough bread, 

We will be measuring interest in sourdough bread using Google Trends data in the USA. Google Trends tracks the popularity of different search terms over time. We will be comparing the popularity of the search term "sourdough" against the control groups: the search terms "cereal," "soup," and "sandwich," the popularity of which we suspect might not have been meaningfully affected by COVID lockdowns.


```{r}
sr <- read.csv("C:/Users/braul/OneDrive - Duke University/1. First Year/3. Stats/HW docs/sourdough_trends.csv")

sr <- sr |> select(date, hits, keyword) 

eventdate <- as.Date('2020-03-15')

sr$date <- as.Date(sr$date)

```

### 2. Make a line graph with `date` on the x-axis and `hits` on the y-axis, with a separate line for each `keyword`. Also add a vertical line for the "start of the pandemic" which we'll decide for our purposes is March 15, 2020.

```{r}

sr |> ggplot(aes(date,hits,col=keyword)) + geom_line() + geom_vline(aes(xintercept = eventdate),linetype=4)  
  
```



### 3. Looking at your graph from problem 2, comment on (a) whether it looks like the lockdown had an effect on the popularity of sourdough, (b) the shape that effect takes (i.e. is it a permanent increase in popularity? Temporary?), (c) whether you might be concerned about any of the control groups we've chosen

_a) There is a clear peak in sourdough google searches after the pandemic started._

_b) The shape of the effect takes the form of a first peak at the beggining of April which  plateaus until May and then starts descending_ 

_c) I am concerned about soup because it seems that the pandemic changed the direction of the trend, from a decrease to an increase. Sandwich also exhibits an uneasy trend but I wouldn't be too much worried about it. Cereal is probably the best control._



### 4. Create a "Treated" indicator that's equal to 1 for sourdough and 0 otherwise (or True/False, either way). Do a test of whether the prior trends (keeping March 15 as the "treatment date") differ between the treated and control groups, using a linear trend and doing a statistical significance test at the 95% level. Then, if you were concerned about any of the control groups in question 3c, drop any you were concerned about (and keep them dropped for the rest of the assignment) and rerun the test.

Write a line commenting on whether you can reject equal prior trends in your model(s).

```{r}

# Create sourdough variable
sr <- sr |> mutate(treated=if_else(keyword=="sourdough",1,0),
                   pre_treatp=if_else(date<eventdate,1,0)) 

# Choose only pre-treatment period
sr_pre <- sr |> filter(pre_treatp==1) 

sr_pre$keyword <- relevel(factor(sr_pre$keyword), ref="sourdough")

# See interactions between treatment and date 
m1 <- lm(hits ~ keyword*date,data=sr_pre)


m2 <- lm(hits ~ treated*date,data=sr_pre)

tidy(m1, conf.int = TRUE)

```


_Here we see that the effect of soup on hits depends on the time period. This casts doubt on the parallel trend assumption because we are on the pre-treatment period, where we shouldn't have variation on the trends._

_However, if we include soup with the other ones as one category (the untreated), then this interaction effect disappears:_

```{r}
tidy(m2, conf.int = TRUE)
```



_I will run the regression again without soup nor sandwich :_

```{r}
# Remove soup
sr_pre_nos<- sr_pre |> filter(keyword!="soup" & keyword!="sandwich")

tidy(lm(hits ~ keyword*date,data=sr_pre_nos),conf.int = TRUE)

```

_We confirm that cereal is the best control to answer this question. If we only used cereal, then we can confirm that the parallel trend assumption is verified in this case_


### 5. Create a `month` variable by shifting the `date` variable back 15 days (so that the treatment day is the first day of the month) and then taking the month of the resulting date. Also create an `After` variable equal to 1/0 (or True/False) if the date is March 15 or afterwards.

```{r}
library(lubridate)
sr2 <- sr |> mutate(month=month(date-days(14)), 
                    after=if_else(date>=eventdate,1,0)) 
```


Then, take a look at the values of `month` you get and how they line up with `date`, and subtract a number from `month` so that the last period just before treatment (Feb 16-Mar 14) is 0. (Also, change the Jan 1-14 month so it's one less than the Jan 15-Feb 14 month)

```{r}
sr2 <- sr2 |> mutate(month = if_else(month==12,-2,month-2))
```


Then, use two-way fixed effects to estimate the difference-in-difference estimate of the effect of lockdown on sourdough popularity with `keyword` and `month` fixed effects, and standard errors clustered at the `keyword` level.



_First, I try a model with all the keywords:_

```{r}
sr2 <- sr2 |> mutate(treatednow = if_else(treated==1 & after==1,1,0))
m3 <- feols(hits ~ treatednow | keyword + month, data=sr2) 
tidy(m3, conf.int = TRUE)
```

_Results does not show support for the hypothesis for lockdown. In the next model, I only include sourdough and cereal_ 


```{r}

sr2_ns <- sr2 |> filter(keyword=="sourdough" | keyword=="cereal")
m3_1 <- feols(hits ~ treatednow | keyword + month, data=sr2_ns) 

tidy(m3_1, conf.int = TRUE)

```

_Using only cereal as the untreated group, we are confident to say that the pandemic lock down increased by 8 hit points the searches for sourdough bread in contrast to cereal. We can be confident at the 95% level that this effect is different than zero_


### 6. Now, let's allow the effect to be dynamic over time. Estimate a difference-in-difference model allowing the effect to differ by month (using `month = 0` as a reference period), with standard errors clustered at the keyword level, and show the results.

_I adjusted three models, one with all the keywords, another one only with soup and sourdough, and another one with only cereal and sourdough_


```{r}
m4 <- feols(hits ~ i(month, treated, ref=0) | keyword + month, data=sr2) 
m4.1 <- feols(hits ~ i(month, treated, ref=0) | keyword + month, data=sr2_ns) 

sr2_justsoup <- sr2 |> filter(keyword!= "cereal" & keyword!= "sandwich")

m4.2 <- feols(hits ~ i(month, treated, ref=0) | keyword + month, data=sr2_justsoup) 
```


### 7. Make a graph demonstrating the results of your dynamic difference-in-differences model. Describe both what the effect looks like and also whether this graph gives you any concerns about prior trends violations.

```{r}
coefplot(list(m4,m4.1))  
```

_The triangles is the model with only cereal and sourdhough, and the circles the model with every keyword. we can see that in both cases, the estimates show a positive trend in every month. This trend reaches its peak in month 1 and 2 and then declines in 3 4 and 5. The only differences between the models are with respect to their standard errors, which make sense because as we saw earlier, the trends of soup and sandwich violated the parallel trend assumption._

_When we add the model only with the sourdough-soup comparison we see how the parallel trend assumption is violated (green squares on the plot). We also see how the soup is driving the standard errors up in the model that includes all the keywords_



```{r}
coefplot(list(m4,m4.1, m4.2))  
```

